{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import regex as reg\n",
    "import os\n",
    "from pathlib import Path\n",
    "#NLP\n",
    "import spacy as sp\n",
    "from nltk.corpus import opinion_lexicon\n",
    "#sklearn\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#Serialization \n",
    "import dill\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('tweet_sentiment.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(opinion_lexicon.negative())\n",
    "len(opinion_lexicon.positive())\n",
    "#for w in range(len(opinion_lexicon.negative())):\n",
    "#              opinion_lexicon.negative()[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = Path.home() \n",
    "path = Path(filepath)\n",
    "list_of_files = path / 'DSI/ClientProject/Tweets_511'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame()\n",
    "for p in list_of_files.iterdir():\n",
    "    temp_df = pd.read_csv(p,usecols = ['tweet_id','text','region'])\n",
    "    tweet_df = tweet_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 130092 entries, 0 to 17\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   tweet_id  130092 non-null  object\n",
      " 1   text      130089 non-null  object\n",
      " 2   region    130086 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tweet_id    0\n",
       "text        3\n",
       "region      6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.info()\n",
    "tweet_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.drop_duplicates(subset = 'tweet_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 92325 entries, 0 to 17\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   tweet_id  92325 non-null  object\n",
      " 1   text      92323 non-null  object\n",
      " 2   region    92321 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tweet_id    0\n",
       "text        2\n",
       "region      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.info()\n",
    "tweet_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 92319 entries, 0 to 17\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   tweet_id  92319 non-null  object\n",
      " 1   text      92319 non-null  object\n",
      " 2   region    92319 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tweet_id    0\n",
       "text        0\n",
       "region      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.dropna(inplace=True)\n",
    "tweet_df.info()\n",
    "tweet_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.reset_index(inplace=True)\n",
    "tweet_df = tweet_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1246588222903214080</td>\n",
       "      <td>Shaukat Khanum Memorial Cancer Hospital offers...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1246587645779574784</td>\n",
       "      <td>Church congregants insisting on attending serv...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1246585369899892738</td>\n",
       "      <td>Rendering of a new 44-unit affordable housing ...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1246584511732695040</td>\n",
       "      <td>Double date, covid-style. pic.twitter.com/LWh2...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1246584386583068672</td>\n",
       "      <td>Si tuvieran que sacrificar un pueblo para acab...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1246584366471376896</td>\n",
       "      <td>El Covid-19 iba a llamarse Dolly Parton, pero ...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1246584353821315073</td>\n",
       "      <td>20-20  is perfect Vision but as a year 2020 is...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1246583763267514368</td>\n",
       "      <td>S/o to the homie @yerrrchubbs for being on liv...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1246583102534639617</td>\n",
       "      <td>Going on a road trip  fuck covid</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1246582098523115520</td>\n",
       "      <td>@greggutfeld We are given these numbers about ...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1246581635866415105</td>\n",
       "      <td>#covid-19 #coronavirus @ Long Beach, Californi...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1246581609559502849</td>\n",
       "      <td>Meanwhile, the president is saying he’s going ...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1246580557430976512</td>\n",
       "      <td>Serious question, if a model was used on #’s w...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1246580280313274368</td>\n",
       "      <td>@DonaldJTrumpJr I hope and pray your dad is no...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1246579907540529157</td>\n",
       "      <td>Nature’s brush strokes #sunset in a time of co...</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index             tweet_id  \\\n",
       "0       0  1246588222903214080   \n",
       "1       1  1246587645779574784   \n",
       "2       2  1246585369899892738   \n",
       "3       3  1246584511732695040   \n",
       "4       4  1246584386583068672   \n",
       "5       5  1246584366471376896   \n",
       "6       6  1246584353821315073   \n",
       "7       7  1246583763267514368   \n",
       "8       8  1246583102534639617   \n",
       "9       9  1246582098523115520   \n",
       "10     10  1246581635866415105   \n",
       "11     11  1246581609559502849   \n",
       "12     12  1246580557430976512   \n",
       "13     13  1246580280313274368   \n",
       "14     14  1246579907540529157   \n",
       "\n",
       "                                                 text region  \n",
       "0   Shaukat Khanum Memorial Cancer Hospital offers...     LA  \n",
       "1   Church congregants insisting on attending serv...     LA  \n",
       "2   Rendering of a new 44-unit affordable housing ...     LA  \n",
       "3   Double date, covid-style. pic.twitter.com/LWh2...     LA  \n",
       "4   Si tuvieran que sacrificar un pueblo para acab...     LA  \n",
       "5   El Covid-19 iba a llamarse Dolly Parton, pero ...     LA  \n",
       "6   20-20  is perfect Vision but as a year 2020 is...     LA  \n",
       "7   S/o to the homie @yerrrchubbs for being on liv...     LA  \n",
       "8                    Going on a road trip  fuck covid     LA  \n",
       "9   @greggutfeld We are given these numbers about ...     LA  \n",
       "10  #covid-19 #coronavirus @ Long Beach, Californi...     LA  \n",
       "11  Meanwhile, the president is saying he’s going ...     LA  \n",
       "12  Serious question, if a model was used on #’s w...     LA  \n",
       "13  @DonaldJTrumpJr I hope and pray your dad is no...     LA  \n",
       "14  Nature’s brush strokes #sunset in a time of co...     LA  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = sp.load('en_core_web_sm')\n",
    "processed_tweet = []\n",
    "\n",
    "def clean_tweet(text):\n",
    "\n",
    "#replace anything that isn't a-z or A-Z with spaces including punctuations, exclamation etc\n",
    "#replace 'https://', 'www.' by space \n",
    "    ret_str = ' '\n",
    "    regex = r\"(.\\\\n|.\\\\t|.\\\\r)|([0-9]+)|([^\\w\\s])|(https{0,1}:\\/\\/\\S*)|(ww[wa-zA-Z0-9.com]+)|(pic.twitter\\S*)\"\n",
    "    ret_str = reg.sub(regex, '', str(text))\n",
    "    ret_str = ret_str.rstrip() \n",
    "    ret_str = ret_str.lstrip()\n",
    "    ret_str = ret_str.lower()\n",
    "    doc = spacy_nlp(ret_str)\n",
    "    all_lemmas =  [token.lemma_ for token in doc if  not token.is_stop \\\n",
    "                   and token.is_alpha and token.lemma_ != '-PRON-']\n",
    "    processed_tweet.append(\" \".join(all_lemmas)) # tweet cleaned up,tokenized.Copy each tweet as a string to the list\n",
    "    return all_lemmas #tweet cleaned up, tokenized return a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet():\n",
    "    clean_tweets = []\n",
    "    start = time.perf_counter()\n",
    "    counter = 0\n",
    "    for row in tweet_df['text']:\n",
    "        clean_tweets.append(clean_tweet(row))\n",
    "        counter += 1\n",
    "        \n",
    "    print(f\"Processed {counter} rows in training data\")\n",
    "\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    print(f\"Took { round((end-start)/60,0)} minutes to clean\")\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 92319 rows in training data\n",
      "Took 14.0 minutes to clean\n"
     ]
    }
   ],
   "source": [
    "tweet_tokens = process_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 rows\n",
      "Processed 20000 rows\n",
      "Processed 30000 rows\n",
      "Processed 40000 rows\n",
      "Processed 50000 rows\n",
      "Processed 60000 rows\n",
      "Processed 70000 rows\n",
      "Processed 80000 rows\n",
      "Processed 90000 rows\n",
      "Took 276.0 minutes for sentiment analysis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92319"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0 \n",
    "sentiment = []\n",
    "start = time.perf_counter()\n",
    "\n",
    "for tokens in tweet_tokens:\n",
    "    positive_words = 0\n",
    "    negative_words = 0\n",
    "    count += 1\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in opinion_lexicon.positive():\n",
    "            positive_words += 1\n",
    "        elif tokens[i] in opinion_lexicon.negative():\n",
    "            negative_words += 1\n",
    "        \n",
    "    if positive_words > negative_words:\n",
    "        sentiment.append(1) #postive\n",
    "    elif positive_words < negative_words:\n",
    "        sentiment.append(-1) #negative\n",
    "    elif positive_words == negative_words:\n",
    "        sentiment.append(0) #neutral\n",
    "        \n",
    "    if count%10_000 == 0:\n",
    "        print(f\"Processed {count} rows\")\n",
    "            \n",
    "end = time.perf_counter()\n",
    "print(f\"Took { round((end-start)/60,0)} minutes for sentiment analysis\")          \n",
    "\n",
    "len(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['tweettokens'] = tweet_tokens\n",
    "tweet_df['processedtweet'] = processed_tweet\n",
    "tweet_df['sentiment'] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92319 entries, 0 to 92318\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   index           92319 non-null  int64 \n",
      " 1   tweet_id        92319 non-null  object\n",
      " 2   text            92319 non-null  object\n",
      " 3   region          92319 non-null  object\n",
      " 4   tweettokens     92319 non-null  object\n",
      " 5   processedtweet  92319 non-null  object\n",
      " 6   sentiment       92319 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 4.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>region</th>\n",
       "      <th>tweettokens</th>\n",
       "      <th>processedtweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1246588222903214080</td>\n",
       "      <td>Shaukat Khanum Memorial Cancer Hospital offers...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[shaukat, khanum, memorial, cancer, hospital, ...</td>\n",
       "      <td>shaukat khanum memorial cancer hospital offer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1246587645779574784</td>\n",
       "      <td>Church congregants insisting on attending serv...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[church, congregant, insist, attend, service, ...</td>\n",
       "      <td>church congregant insist attend service wake c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1246585369899892738</td>\n",
       "      <td>Rendering of a new 44-unit affordable housing ...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[render, new, unit, affordable, housing, proje...</td>\n",
       "      <td>render new unit affordable housing project hav...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1246584511732695040</td>\n",
       "      <td>Double date, covid-style. pic.twitter.com/LWh2...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[double, date, covidstyle]</td>\n",
       "      <td>double date covidstyle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1246584386583068672</td>\n",
       "      <td>Si tuvieran que sacrificar un pueblo para acab...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[si, tuvieran, que, sacrificar, un, pueblo, pa...</td>\n",
       "      <td>si tuvieran que sacrificar un pueblo para acab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             tweet_id  \\\n",
       "0      0  1246588222903214080   \n",
       "1      1  1246587645779574784   \n",
       "2      2  1246585369899892738   \n",
       "3      3  1246584511732695040   \n",
       "4      4  1246584386583068672   \n",
       "\n",
       "                                                text region  \\\n",
       "0  Shaukat Khanum Memorial Cancer Hospital offers...     LA   \n",
       "1  Church congregants insisting on attending serv...     LA   \n",
       "2  Rendering of a new 44-unit affordable housing ...     LA   \n",
       "3  Double date, covid-style. pic.twitter.com/LWh2...     LA   \n",
       "4  Si tuvieran que sacrificar un pueblo para acab...     LA   \n",
       "\n",
       "                                         tweettokens  \\\n",
       "0  [shaukat, khanum, memorial, cancer, hospital, ...   \n",
       "1  [church, congregant, insist, attend, service, ...   \n",
       "2  [render, new, unit, affordable, housing, proje...   \n",
       "3                         [double, date, covidstyle]   \n",
       "4  [si, tuvieran, que, sacrificar, un, pueblo, pa...   \n",
       "\n",
       "                                      processedtweet  sentiment  \n",
       "0  shaukat khanum memorial cancer hospital offer ...          0  \n",
       "1  church congregant insist attend service wake c...          0  \n",
       "2  render new unit affordable housing project hav...         -1  \n",
       "3                             double date covidstyle          0  \n",
       "4  si tuvieran que sacrificar un pueblo para acab...          0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.info()\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    0.373303\n",
       "-1    0.322675\n",
       " 1    0.304022\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df['sentiment'].value_counts(normalize = True)\n",
    "# 0 - neutral, 1 - positive, -1 - negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                             0\n",
       "tweet_id                                        1246588222903214080\n",
       "text              Shaukat Khanum Memorial Cancer Hospital offers...\n",
       "region                                                           LA\n",
       "tweettokens       [shaukat, khanum, memorial, cancer, hospital, ...\n",
       "processedtweet    shaukat khanum memorial cancer hospital offer ...\n",
       "sentiment                                                         0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_df['processedtweet']\n",
    "y = tweet_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61853,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(30466,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(30466,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(61853,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.33,random_state = 111)\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "y_test.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(gsobject,xdata,ydata):\n",
    "    predicted = gsobject.predict(xdata)\n",
    "    actual_predicted = pd.DataFrame({\"Actual\" : ydata, \"Predicted\": predicted, 'Text': xdata})\n",
    "    return actual_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gs_type = grid search object\n",
    "#xtraindata,xtestdata = xtrain and xtest \n",
    "#ytraindata,ytest = ytrain and ytest\n",
    "def fit_grid_search(gs_type,xtraindata,ytraindata,xtestdata,ytestdata):\n",
    "    start = time.perf_counter()\n",
    "    gs_type.fit(xtraindata,ytraindata)\n",
    "    print(f\"Grid search accuracy for estimator \\033[1m{gs_type.estimator.steps[1][0]}\\033[0m \"\n",
    "          f\"transformer \\033[1m{gs_type.estimator.steps[0][0]}\\033[0m : \\n\")\n",
    "    print(f\"On training data is {gs_type.score(xtraindata,ytraindata)}\")\n",
    "    print(f\"On test data is {gs_type.score(xtestdata,ytestdata)}\")\n",
    "    print(f\"Grid search best score (avg of cv scores) {gs_type.best_score_}\\n\\n\")\n",
    "    print(f\"Model with best fitting parameter is \\n {gs_type.best_estimator_.get_params}\\n\\n\")\n",
    "    #print(gs_type.best_estimator_.named_steps['logisticregression'].coef_)\n",
    "    end = time.perf_counter()\n",
    "    print(f\"Took \\033[1m{ round((end-start)/60,0)}\\033[0m minutes to complete\")\n",
    "    cv_results_df = pd.DataFrame(gs_type.cv_results_)\n",
    "    return cv_results_df,gs_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette_tfidf = make_pipeline(TfidfVectorizer(),LogisticRegression())\n",
    "pipe_params_tfidf = {\n",
    "    'tfidfvectorizer__max_features': [15_000,25_000,30_000],\n",
    "    'tfidfvectorizer__ngram_range': [ (1,2),(1,3)],\n",
    "    'tfidfvectorizer__min_df' : [5,10], #discard words that appear in less than 5 or 10 documents\n",
    "    'tfidfvectorizer__max_df' : [0.80], #exclude words that cross this threshold(how many documents contained a term)\n",
    "    'tfidfvectorizer__stop_words' : [None],\n",
    "    'logisticregression__max_iter': [1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_tfidf = GridSearchCV(pipette_tfidf, \n",
    "                  pipe_params_tfidf, \n",
    "                  cv = 5 ,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search accuracy for estimator \u001b[1mlogisticregression\u001b[0m transformer \u001b[1mtfidfvectorizer\u001b[0m : \n",
      "\n",
      "On training data is 0.8878954941554977\n",
      "On test data is 0.828169106545001\n",
      "Grid search best score (avg of cv scores) 0.8144632448419834\n",
      "\n",
      "\n",
      "Model with best fitting parameter is \n",
      " <bound method Pipeline.get_params of Pipeline(memory=None,\n",
      "         steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=0.8, max_features=15000,\n",
      "                                 min_df=10, ngram_range=(1, 2), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 sublinear_tf=False,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=1000,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)>\n",
      "\n",
      "\n",
      "Took \u001b[1m10.0\u001b[0m minutes to complete\n"
     ]
    }
   ],
   "source": [
    "results_tfidf,gs_tfidf = fit_grid_search(gs_tfidf,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining set data\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>let support elon musk elonmusk battle leviatha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89173</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>acid queen retake covid queen be covid pay tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23513</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>agree gov newsom issue pretty good job handle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47415</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>painting covid era desert dusk oil canvas x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36882</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shiny shop shuttered beverlyhill covid pandemi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35662</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>take action ask ny legislature governor cuomo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19595</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>potus know old citizen age group infect covid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38497</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>confusion date federal filling payment july th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28118</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>have quarantine year not wanna motherfucker st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>wanna shoot itch dodge beginning quarantine pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6934 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted                                               Text\n",
       "7580        0          1  let support elon musk elonmusk battle leviatha...\n",
       "89173       1          0  acid queen retake covid queen be covid pay tes...\n",
       "23513       0          1  agree gov newsom issue pretty good job handle ...\n",
       "47415      -1          0        painting covid era desert dusk oil canvas x\n",
       "36882       1          0  shiny shop shuttered beverlyhill covid pandemi...\n",
       "...       ...        ...                                                ...\n",
       "35662       0         -1  take action ask ny legislature governor cuomo ...\n",
       "19595       0          1  potus know old citizen age group infect covid ...\n",
       "38497      -1          0  confusion date federal filling payment july th...\n",
       "28118       1          0  have quarantine year not wanna motherfucker st...\n",
       "10658      -1          0  wanna shoot itch dodge beginning quarantine pa...\n",
       "\n",
       "[6934 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTesting set data\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26903</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>joebiden human sane person vote governor covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21546</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>bernie pony cash corona virus vaccine free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16171</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>trump say restart economy brutish political id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50943</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>sure protect covid burn clothe end day add cup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85249</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>wonderful world hưng blackheart diy video stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82183</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>cmon jam not close able american social distan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21094</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>ha right trump assure corona virus problem lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>like bad bewitch spinoff karma twin cousin cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not miss tomorrow covid webinar great panel im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24073</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>tяump choice help american work nancypelosi co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5235 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted                                               Text\n",
       "26903       1          0  joebiden human sane person vote governor covid...\n",
       "21546       0         -1         bernie pony cash corona virus vaccine free\n",
       "16171       0          1  trump say restart economy brutish political id...\n",
       "50943       0          1  sure protect covid burn clothe end day add cup...\n",
       "85249       1          0  wonderful world hưng blackheart diy video stay...\n",
       "...       ...        ...                                                ...\n",
       "82183      -1          0  cmon jam not close able american social distan...\n",
       "21094       1         -1  ha right trump assure corona virus problem lov...\n",
       "3373        0          1  like bad bewitch spinoff karma twin cousin cor...\n",
       "15814       0          1  not miss tomorrow covid webinar great panel im...\n",
       "24073      -1          1  tяump choice help american work nancypelosi co...\n",
       "\n",
       "[5235 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\033[1mTraining set data\\033[0m\")\n",
    "actual_v_predicted_train= conf_matrix(gs_tfidf,X_train,y_train)\n",
    "\n",
    "mask = actual_v_predicted_train[(actual_v_predicted_train['Actual']) != (actual_v_predicted_train['Predicted'])]\n",
    "mask\n",
    "\n",
    "print(f\"\\033[1mTesting set data\\033[0m\")\n",
    "actual_v_predicted_test = conf_matrix(gs_tfidf,X_test,y_test)\n",
    "\n",
    "mask = actual_v_predicted_test[(actual_v_predicted_test['Actual']) != (actual_v_predicted_test['Predicted'])]\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipette_cvect = make_pipeline(CountVectorizer(),LogisticRegression())\n",
    "pipe_params_cvect = {\n",
    "    'countvectorizer__max_features': [15_000,25_000,30_000],\n",
    "    'countvectorizer__ngram_range':  [(1,2),(1,3)],\n",
    "    'countvectorizer__min_df' : [5,10], #discard words that appear in less than 5 or 10 documents\n",
    "    'countvectorizer__max_df' : [0.8], #exclude words that cross this threshold(how many docs contained a term)\n",
    "    'countvectorizer__stop_words' : [None],\n",
    "    'logisticregression__max_iter': [1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cvect = GridSearchCV(pipette_cvect, \n",
    "                  pipe_params_cvect, \n",
    "                  cv = 5,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search accuracy for estimator \u001b[1mlogisticregression\u001b[0m transformer \u001b[1mcountvectorizer\u001b[0m : \n",
      "\n",
      "On training data is 0.962168366934506\n",
      "On test data is 0.8778966716995995\n",
      "Grid search best score (avg of cv scores) 0.859925934430714\n",
      "\n",
      "\n",
      "Model with best fitting parameter is \n",
      " <bound method Pipeline.get_params of Pipeline(memory=None,\n",
      "         steps=[('countvectorizer',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=0.8,\n",
      "                                 max_features=15000, min_df=10,\n",
      "                                 ngram_range=(1, 2), preprocessor=None,\n",
      "                                 stop_words=None, strip_accents=None,\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, vocabulary=None)),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                    fit_intercept=True, intercept_scaling=1,\n",
      "                                    l1_ratio=None, max_iter=1000,\n",
      "                                    multi_class='auto', n_jobs=None,\n",
      "                                    penalty='l2', random_state=None,\n",
      "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                                    warm_start=False))],\n",
      "         verbose=False)>\n",
      "\n",
      "\n",
      "Took \u001b[1m11.0\u001b[0m minutes to complete\n"
     ]
    }
   ],
   "source": [
    "results_cvect,gs_cvect = fit_grid_search(gs_cvect,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining set data\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89173</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>acid queen retake covid queen be covid pay tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23513</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>agree gov newsom issue pretty good job handle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36882</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>shiny shop shuttered beverlyhill covid pandemi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>imagine work class people not child test covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>impact covid discriminate ensure equal access ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>go iphone photo delete dumb one perfect activi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85654</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>artist lover need voice hear keepartswork arts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21736</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>defeat corona virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79942</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not sound good coronavirus alert rare syndrome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>coincidentally success rate sbs generally unaf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2340 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted                                               Text\n",
       "89173       1          0  acid queen retake covid queen be covid pay tes...\n",
       "23513       0          1  agree gov newsom issue pretty good job handle ...\n",
       "36882       1          0  shiny shop shuttered beverlyhill covid pandemi...\n",
       "35999       0          1  imagine work class people not child test covid...\n",
       "6890       -1          0  impact covid discriminate ensure equal access ...\n",
       "...       ...        ...                                                ...\n",
       "2338        1          0  go iphone photo delete dumb one perfect activi...\n",
       "85654       1          0  artist lover need voice hear keepartswork arts...\n",
       "21736       0         -1                                defeat corona virus\n",
       "79942       0          1  not sound good coronavirus alert rare syndrome...\n",
       "2611        0         -1  coincidentally success rate sbs generally unaf...\n",
       "\n",
       "[2340 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTesting set data\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85249</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>wonderful world hưng blackheart diy video stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80757</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lose job covid yes buy ticket good friend kare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13656</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>governor executive order prevent community spr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>kind slap face work sacrifice wear mask opinio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61613</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>happy friday hopefully sun weekend remember lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20506</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>feel like reason response covid bad realdonald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35143</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>hop find path forward allow continue dogather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>like bad bewitch spinoff karma twin cousin cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>not miss tomorrow covid webinar great panel im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24073</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>tяump choice help american work nancypelosi co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3720 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted                                               Text\n",
       "85249       1          0  wonderful world hưng blackheart diy video stay...\n",
       "80757       0          1  lose job covid yes buy ticket good friend kare...\n",
       "13656      -1          0  governor executive order prevent community spr...\n",
       "6353        0          1  kind slap face work sacrifice wear mask opinio...\n",
       "61613       0          1  happy friday hopefully sun weekend remember lo...\n",
       "...       ...        ...                                                ...\n",
       "20506       0         -1  feel like reason response covid bad realdonald...\n",
       "35143       0          1  hop find path forward allow continue dogather ...\n",
       "3373        0          1  like bad bewitch spinoff karma twin cousin cor...\n",
       "15814       0         -1  not miss tomorrow covid webinar great panel im...\n",
       "24073      -1          1  tяump choice help american work nancypelosi co...\n",
       "\n",
       "[3720 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\033[1mTraining set data\\033[0m\")\n",
    "actual_v_predicted_train= conf_matrix(gs_cvect,X_train,y_train)\n",
    "\n",
    "mask = actual_v_predicted_train[(actual_v_predicted_train['Actual']) != (actual_v_predicted_train['Predicted'])]\n",
    "mask\n",
    "\n",
    "print(f\"\\033[1mTesting set data\\033[0m\")\n",
    "actual_v_predicted_test = conf_matrix(gs_cvect,X_test,y_test)\n",
    "\n",
    "mask = actual_v_predicted_test[(actual_v_predicted_test['Actual']) != (actual_v_predicted_test['Predicted'])]\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.merge(tweet_df,actual_v_predicted_test[['Predicted']],how = 'left', left_index= True, right_index=True)\n",
    "output_df = pd.merge(output_df,actual_v_predicted_train[['Predicted']],how = 'left', left_index= True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>region</th>\n",
       "      <th>tweettokens</th>\n",
       "      <th>processedtweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Predicted_x</th>\n",
       "      <th>Predicted_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1246588222903214080</td>\n",
       "      <td>Shaukat Khanum Memorial Cancer Hospital offers...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[shaukat, khanum, memorial, cancer, hospital, ...</td>\n",
       "      <td>shaukat khanum memorial cancer hospital offer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1246587645779574784</td>\n",
       "      <td>Church congregants insisting on attending serv...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[church, congregant, insist, attend, service, ...</td>\n",
       "      <td>church congregant insist attend service wake c...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1246585369899892738</td>\n",
       "      <td>Rendering of a new 44-unit affordable housing ...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[render, new, unit, affordable, housing, proje...</td>\n",
       "      <td>render new unit affordable housing project hav...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1246584511732695040</td>\n",
       "      <td>Double date, covid-style. pic.twitter.com/LWh2...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[double, date, covidstyle]</td>\n",
       "      <td>double date covidstyle</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1246584386583068672</td>\n",
       "      <td>Si tuvieran que sacrificar un pueblo para acab...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[si, tuvieran, que, sacrificar, un, pueblo, pa...</td>\n",
       "      <td>si tuvieran que sacrificar un pueblo para acab...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index             tweet_id  \\\n",
       "0        0      0  1246588222903214080   \n",
       "1        1      1  1246587645779574784   \n",
       "2        2      2  1246585369899892738   \n",
       "3        3      3  1246584511732695040   \n",
       "4        4      4  1246584386583068672   \n",
       "\n",
       "                                                text region  \\\n",
       "0  Shaukat Khanum Memorial Cancer Hospital offers...     LA   \n",
       "1  Church congregants insisting on attending serv...     LA   \n",
       "2  Rendering of a new 44-unit affordable housing ...     LA   \n",
       "3  Double date, covid-style. pic.twitter.com/LWh2...     LA   \n",
       "4  Si tuvieran que sacrificar un pueblo para acab...     LA   \n",
       "\n",
       "                                         tweettokens  \\\n",
       "0  [shaukat, khanum, memorial, cancer, hospital, ...   \n",
       "1  [church, congregant, insist, attend, service, ...   \n",
       "2  [render, new, unit, affordable, housing, proje...   \n",
       "3                         [double, date, covidstyle]   \n",
       "4  [si, tuvieran, que, sacrificar, un, pueblo, pa...   \n",
       "\n",
       "                                      processedtweet  sentiment  Predicted_x  \\\n",
       "0  shaukat khanum memorial cancer hospital offer ...          0          0.0   \n",
       "1  church congregant insist attend service wake c...          0          NaN   \n",
       "2  render new unit affordable housing project hav...         -1         -1.0   \n",
       "3                             double date covidstyle          0          NaN   \n",
       "4  si tuvieran que sacrificar un pueblo para acab...          0          NaN   \n",
       "\n",
       "   Predicted_y  \n",
       "0          NaN  \n",
       "1          0.0  \n",
       "2          NaN  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>region</th>\n",
       "      <th>tweettokens</th>\n",
       "      <th>processedtweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Predicted_x</th>\n",
       "      <th>Predicted_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92314</th>\n",
       "      <td>92314</td>\n",
       "      <td>13</td>\n",
       "      <td>1259997652449669121</td>\n",
       "      <td>A possibility that #COVID19 survivors’ blood c...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[possibility, covid, survivor, blood, develop,...</td>\n",
       "      <td>possibility covid survivor blood develop treat...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92315</th>\n",
       "      <td>92315</td>\n",
       "      <td>14</td>\n",
       "      <td>1259996984682872833</td>\n",
       "      <td>Stepping up to provide #DirectCashAssistance t...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[step, provide, directcashassistance, help, la...</td>\n",
       "      <td>step provide directcashassistance help la crea...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92316</th>\n",
       "      <td>92316</td>\n",
       "      <td>15</td>\n",
       "      <td>1259996804856401920</td>\n",
       "      <td>Free webinar this Friday on how to pivot your ...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[free, webinar, friday, pivot, smallbiz, join,...</td>\n",
       "      <td>free webinar friday pivot smallbiz join pcvtwe...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92317</th>\n",
       "      <td>92317</td>\n",
       "      <td>16</td>\n",
       "      <td>1259996787496022016</td>\n",
       "      <td>What support looks like in action — @jihern_ &amp;...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[support, look, like, action, jihern, poufu, l...</td>\n",
       "      <td>support look like action jihern poufu learn mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92318</th>\n",
       "      <td>92318</td>\n",
       "      <td>17</td>\n",
       "      <td>1259996720060039168</td>\n",
       "      <td>‘YodiYil’ Offers #Free #GPSTracker For Custome...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[yodiyil, offer, free, gpstracker, customer, d...</td>\n",
       "      <td>yodiyil offer free gpstracker customer directl...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       level_0  index             tweet_id  \\\n",
       "92314    92314     13  1259997652449669121   \n",
       "92315    92315     14  1259996984682872833   \n",
       "92316    92316     15  1259996804856401920   \n",
       "92317    92317     16  1259996787496022016   \n",
       "92318    92318     17  1259996720060039168   \n",
       "\n",
       "                                                    text region  \\\n",
       "92314  A possibility that #COVID19 survivors’ blood c...     SF   \n",
       "92315  Stepping up to provide #DirectCashAssistance t...     SF   \n",
       "92316  Free webinar this Friday on how to pivot your ...     SF   \n",
       "92317  What support looks like in action — @jihern_ &...     SF   \n",
       "92318  ‘YodiYil’ Offers #Free #GPSTracker For Custome...     SF   \n",
       "\n",
       "                                             tweettokens  \\\n",
       "92314  [possibility, covid, survivor, blood, develop,...   \n",
       "92315  [step, provide, directcashassistance, help, la...   \n",
       "92316  [free, webinar, friday, pivot, smallbiz, join,...   \n",
       "92317  [support, look, like, action, jihern, poufu, l...   \n",
       "92318  [yodiyil, offer, free, gpstracker, customer, d...   \n",
       "\n",
       "                                          processedtweet  sentiment  \\\n",
       "92314  possibility covid survivor blood develop treat...         -1   \n",
       "92315  step provide directcashassistance help la crea...          0   \n",
       "92316  free webinar friday pivot smallbiz join pcvtwe...          1   \n",
       "92317  support look like action jihern poufu learn mo...          1   \n",
       "92318  yodiyil offer free gpstracker customer directl...          1   \n",
       "\n",
       "       Predicted_x  Predicted_y  \n",
       "92314          0.0          NaN  \n",
       "92315          NaN          0.0  \n",
       "92316          NaN          1.0  \n",
       "92317          NaN          1.0  \n",
       "92318          NaN          1.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92319 entries, 0 to 92318\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   level_0         92319 non-null  int64  \n",
      " 1   index           92319 non-null  int64  \n",
      " 2   tweet_id        92319 non-null  object \n",
      " 3   text            92319 non-null  object \n",
      " 4   region          92319 non-null  object \n",
      " 5   tweettokens     92319 non-null  object \n",
      " 6   processedtweet  92319 non-null  object \n",
      " 7   sentiment       92319 non-null  int64  \n",
      " 8   Predicted_x     30466 non-null  float64\n",
      " 9   Predicted_y     61853 non-null  float64\n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "output_df.head()\n",
    "output_df.tail()\n",
    "output_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.drop(columns = 'level_0',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>region</th>\n",
       "      <th>tweettokens</th>\n",
       "      <th>processedtweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Predicted_x</th>\n",
       "      <th>Predicted_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1246588222903214080</td>\n",
       "      <td>Shaukat Khanum Memorial Cancer Hospital offers...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[shaukat, khanum, memorial, cancer, hospital, ...</td>\n",
       "      <td>shaukat khanum memorial cancer hospital offer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1246587645779574784</td>\n",
       "      <td>Church congregants insisting on attending serv...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[church, congregant, insist, attend, service, ...</td>\n",
       "      <td>church congregant insist attend service wake c...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1246585369899892738</td>\n",
       "      <td>Rendering of a new 44-unit affordable housing ...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[render, new, unit, affordable, housing, proje...</td>\n",
       "      <td>render new unit affordable housing project hav...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1246584511732695040</td>\n",
       "      <td>Double date, covid-style. pic.twitter.com/LWh2...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[double, date, covidstyle]</td>\n",
       "      <td>double date covidstyle</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1246584386583068672</td>\n",
       "      <td>Si tuvieran que sacrificar un pueblo para acab...</td>\n",
       "      <td>LA</td>\n",
       "      <td>[si, tuvieran, que, sacrificar, un, pueblo, pa...</td>\n",
       "      <td>si tuvieran que sacrificar un pueblo para acab...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             tweet_id  \\\n",
       "0      0  1246588222903214080   \n",
       "1      1  1246587645779574784   \n",
       "2      2  1246585369899892738   \n",
       "3      3  1246584511732695040   \n",
       "4      4  1246584386583068672   \n",
       "\n",
       "                                                text region  \\\n",
       "0  Shaukat Khanum Memorial Cancer Hospital offers...     LA   \n",
       "1  Church congregants insisting on attending serv...     LA   \n",
       "2  Rendering of a new 44-unit affordable housing ...     LA   \n",
       "3  Double date, covid-style. pic.twitter.com/LWh2...     LA   \n",
       "4  Si tuvieran que sacrificar un pueblo para acab...     LA   \n",
       "\n",
       "                                         tweettokens  \\\n",
       "0  [shaukat, khanum, memorial, cancer, hospital, ...   \n",
       "1  [church, congregant, insist, attend, service, ...   \n",
       "2  [render, new, unit, affordable, housing, proje...   \n",
       "3                         [double, date, covidstyle]   \n",
       "4  [si, tuvieran, que, sacrificar, un, pueblo, pa...   \n",
       "\n",
       "                                      processedtweet  sentiment  Predicted_x  \\\n",
       "0  shaukat khanum memorial cancer hospital offer ...          0          0.0   \n",
       "1  church congregant insist attend service wake c...          0          NaN   \n",
       "2  render new unit affordable housing project hav...         -1         -1.0   \n",
       "3                             double date covidstyle          0          NaN   \n",
       "4  si tuvieran que sacrificar un pueblo para acab...          0          NaN   \n",
       "\n",
       "   Predicted_y  \n",
       "0          NaN  \n",
       "1          0.0  \n",
       "2          NaN  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>region</th>\n",
       "      <th>tweettokens</th>\n",
       "      <th>processedtweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Predicted_x</th>\n",
       "      <th>Predicted_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92314</th>\n",
       "      <td>13</td>\n",
       "      <td>1259997652449669121</td>\n",
       "      <td>A possibility that #COVID19 survivors’ blood c...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[possibility, covid, survivor, blood, develop,...</td>\n",
       "      <td>possibility covid survivor blood develop treat...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92315</th>\n",
       "      <td>14</td>\n",
       "      <td>1259996984682872833</td>\n",
       "      <td>Stepping up to provide #DirectCashAssistance t...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[step, provide, directcashassistance, help, la...</td>\n",
       "      <td>step provide directcashassistance help la crea...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92316</th>\n",
       "      <td>15</td>\n",
       "      <td>1259996804856401920</td>\n",
       "      <td>Free webinar this Friday on how to pivot your ...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[free, webinar, friday, pivot, smallbiz, join,...</td>\n",
       "      <td>free webinar friday pivot smallbiz join pcvtwe...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92317</th>\n",
       "      <td>16</td>\n",
       "      <td>1259996787496022016</td>\n",
       "      <td>What support looks like in action — @jihern_ &amp;...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[support, look, like, action, jihern, poufu, l...</td>\n",
       "      <td>support look like action jihern poufu learn mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92318</th>\n",
       "      <td>17</td>\n",
       "      <td>1259996720060039168</td>\n",
       "      <td>‘YodiYil’ Offers #Free #GPSTracker For Custome...</td>\n",
       "      <td>SF</td>\n",
       "      <td>[yodiyil, offer, free, gpstracker, customer, d...</td>\n",
       "      <td>yodiyil offer free gpstracker customer directl...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index             tweet_id  \\\n",
       "92314     13  1259997652449669121   \n",
       "92315     14  1259996984682872833   \n",
       "92316     15  1259996804856401920   \n",
       "92317     16  1259996787496022016   \n",
       "92318     17  1259996720060039168   \n",
       "\n",
       "                                                    text region  \\\n",
       "92314  A possibility that #COVID19 survivors’ blood c...     SF   \n",
       "92315  Stepping up to provide #DirectCashAssistance t...     SF   \n",
       "92316  Free webinar this Friday on how to pivot your ...     SF   \n",
       "92317  What support looks like in action — @jihern_ &...     SF   \n",
       "92318  ‘YodiYil’ Offers #Free #GPSTracker For Custome...     SF   \n",
       "\n",
       "                                             tweettokens  \\\n",
       "92314  [possibility, covid, survivor, blood, develop,...   \n",
       "92315  [step, provide, directcashassistance, help, la...   \n",
       "92316  [free, webinar, friday, pivot, smallbiz, join,...   \n",
       "92317  [support, look, like, action, jihern, poufu, l...   \n",
       "92318  [yodiyil, offer, free, gpstracker, customer, d...   \n",
       "\n",
       "                                          processedtweet  sentiment  \\\n",
       "92314  possibility covid survivor blood develop treat...         -1   \n",
       "92315  step provide directcashassistance help la crea...          0   \n",
       "92316  free webinar friday pivot smallbiz join pcvtwe...          1   \n",
       "92317  support look like action jihern poufu learn mo...          1   \n",
       "92318  yodiyil offer free gpstracker customer directl...          1   \n",
       "\n",
       "       Predicted_x  Predicted_y  \n",
       "92314          0.0          NaN  \n",
       "92315          NaN          0.0  \n",
       "92316          NaN          1.0  \n",
       "92317          NaN          1.0  \n",
       "92318          NaN          1.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92319 entries, 0 to 92318\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   index           92319 non-null  int64  \n",
      " 1   tweet_id        92319 non-null  object \n",
      " 2   text            92319 non-null  object \n",
      " 3   region          92319 non-null  object \n",
      " 4   tweettokens     92319 non-null  object \n",
      " 5   processedtweet  92319 non-null  object \n",
      " 6   sentiment       92319 non-null  int64  \n",
      " 7   Predicted_x     30466 non-null  float64\n",
      " 8   Predicted_y     61853 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "output_df.head()\n",
    "output_df.tail()\n",
    "output_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('model_loc_sentiment.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
